(IntWritable	1
(status)	1
(tokenizer.hasMoreTokens())	1
+=	1
0;	1
:	1
=	6
Configuration());	1
Context	2
Exception	1
FileInputFormat.setInputPaths(job,	1
FileOutputFormat.setOutputPath(job,	1
IOException,	2
IntWritable(1));	1
IntWritable(sum));	1
IntWritable,	1
IntWritable>	2
InterruptedException	2
Iterable<IntWritable>	1
Job	1
Job.getInstance(new	1
Mapper<LongWritable,	1
MyMapper	1
MyReducer	1
Path(args[0]));	1
Path(args[1]));	1
Reducer<Text,	1
String	1
StringTokenizer	1
StringTokenizer(line);	1
System.exit(0);	1
System.exit(1);	1
Text	2
Text();	1
Text,	3
WordCount	1
args)	1
boolean	1
class	3
context)	2
context.write(key,	1
context.write(word,	1
else	1
extends	2
for	1
if	1
import	14
int	1
java.io.IOException;	1
java.util.*;	1
job	1
job.setInputFormatClass(TextInputFormat.class);	1
job.setJarByClass(WordCount.class);	1
job.setMapperClass(MyMapper.class);	1
job.setOutputFormatClass(TextOutputFormat.class);	1
job.setOutputKeyClass(Text.class);	1
job.setOutputValueClass(IntWritable.class);	1
job.setReducerClass(MyReducer.class);	1
job.waitForCompletion(true);	1
key,	2
line	1
main(String[]	1
map(LongWritable	1
new	6
org.apache.hadoop.conf.Configuration;	1
org.apache.hadoop.fs.Path;	1
org.apache.hadoop.io.IntWritable;	1
org.apache.hadoop.io.LongWritable;	1
org.apache.hadoop.io.Text;	1
org.apache.hadoop.mapreduce.Job;	1
org.apache.hadoop.mapreduce.Mapper;	1
org.apache.hadoop.mapreduce.Reducer;	1
org.apache.hadoop.mapreduce.lib.input.FileInputFormat;	1
org.apache.hadoop.mapreduce.lib.input.TextInputFormat;	1
org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;	1
org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;	1
private	1
public	6
reduce(Text	1
static	3
status	1
sum	2
throws	3
tokenizer	1
val	1
val.get();	1
value,	1
value.toString();	1
values)	1
values,	1
void	3
while	1
word	1
word.set(tokenizer.nextToken());	1
{	10
}	10
